{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Airbnb NY Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "excluding_list = ['price', 'id', 'latitude', 'longitude', 'host_id', 'last_review', \n",
    "                  'name', 'host_name'] #A \n",
    "categorical = ['neighbourhood_group', 'neighbourhood', 'room_type'] #B\n",
    "continuous = ['minimum_nights', 'number_of_reviews', 'reviews_per_month', \n",
    "              'Calculated_host_listings_count'] #C\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/lmassaron/tabular_datasets/master/AB_NYC_2019.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "target_median = (data[\"price\"] > data[\"price\"].median()).astype(int) #D\n",
    "\n",
    "#A list of column names to be excluded from the analysis\n",
    "#B list of names of columns that likely represent categorical variables in the dataset\n",
    "#C list of names of columns that represent continuous numerical variables in the dataset\n",
    "#D a binary balanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing B.1 K-nearest neighbors classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "categorical_onehot_encoding = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "accuracy = make_scorer(accuracy_score) #A\n",
    "cv = KFold(5, shuffle=True, random_state=0) #B\n",
    "model = KNeighborsClassifier(n_neighbors=30, \n",
    "                             weights=\"uniform\",\n",
    "                             algorithm=\"auto\", \n",
    "                             n_jobs=-1) #C\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [('categories', categorical_onehot_encoding, low_card_categorical),\n",
    "     ('numeric', numeric_discretizing, continuous)],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0) #D\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    [('processing', column_transform),\n",
    "     ('pca', PCA(n_components=\"mle\")),\n",
    "     ('modeling', model)]) #E\n",
    "\n",
    "cv_scores = cross_validate(estimator=model_pipeline, \n",
    "                           X=data, \n",
    "                           y=target_median,\n",
    "                           scoring=accuracy,\n",
    "                           cv=cv, \n",
    "                           return_train_score=True,\n",
    "                           return_estimator=True) #F\n",
    "\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"{mean_cv:0.3f} ({std_cv:0.3f})\", \n",
    "      f\"fit: {fit_time:0.2f} secs pred: {score_time:0.2f} secs\") #G\n",
    "\n",
    "#A creating a scoring function using the accuracy_score metric\n",
    "#B creating a five-fold cross-validation iterator with shuffling and a fixed random state\n",
    "#C creating an instance of the KNeighborsClassifier with specified hyperparameters\n",
    "#D defining a ColumnTransformer to preprocess features, applying one-hot encoding to categorical features with low cardinality and discretization to numerical features\n",
    "#E creating a pipeline that sequentially applies the column transformation, performs PCA dimensionality reduction, and then fits the k-nearest neighbors model to the data\n",
    "#F performing cross-validation on the data using the defined pipeline, with accuracy scoring\n",
    "#G  printing the mean and standard deviation of test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb92806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing B.2 Support vector classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_standardization = Pipeline([\n",
    "       (\"imputation\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "       (\"standardizing\", StandardScaler())\n",
    "       ])\n",
    "\n",
    "accuracy = make_scorer(accuracy_score) #A\n",
    "cv = KFold(5, shuffle=True, random_state=0) #B\n",
    "model = SVC(C=1.0, kernel='rbf', gamma='scale', probability=False) #C\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [('categories', categorical_onehot_encoding, low_card_categorical),\n",
    "     ('numeric', numeric_standardization, continuous)],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0) #D\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    [('processing', column_transform),\n",
    "     ('modeling', model)]) #E\n",
    "\n",
    "cv_scores = cross_validate(estimator=model_pipeline, \n",
    "                           X=data, \n",
    "                           y=target_median,\n",
    "                           scoring=accuracy,\n",
    "                           cv=cv, \n",
    "                           return_train_score=True,\n",
    "                           return_estimator=True) #F\n",
    "\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"{mean_cv:0.3f} ({std_cv:0.3f})\", \n",
    "      f\"fit: {fit_time:0.2f} secs pred: {score_time:0.2f} secs\") #G\n",
    "\n",
    "#A creating a scoring function using the accuracy_score metric\n",
    "#B creating a five-fold cross-validation iterator with shuffling and a fixed random state\n",
    "#C creating an instance of the Support Vector Classifier  with specified hyperparameters\n",
    "#D defining a ColumnTransformer to preprocess features, applying one-hot encoding to categorical features with low cardinality and standardization to numerical features\n",
    "#E creating a pipeline that sequentially applies the column transformation and the model to the data\n",
    "#F performing cross-validation on the data using the defined pipeline, with accuracy scoring\n",
    "#G  printing the mean and standard deviation of test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing B.3 Support vector classifier from RAPIDS cuML \n",
    "\n",
    "from cuml.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = make_scorer(accuracy_score) #A\n",
    "cv = KFold(5, shuffle=True, random_state=0) #B\n",
    "model = SVC(C=1.0, kernel='rbf', gamma='scale', probability=False) #C\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [('categories', categorical_onehot_encoding, low_card_categorical),\n",
    "     ('numeric', numeric_standardization, continuous)],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0) #D\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    [('processing', column_transform),\n",
    "     ('modeling', model)]) #E\n",
    "\n",
    "cv_scores = cross_validate(estimator=model_pipeline, \n",
    "                           X=data, \n",
    "                           y=target_median,\n",
    "                           scoring=accuracy,\n",
    "                           cv=cv, \n",
    "                           return_train_score=True,\n",
    "                           return_estimator=True) #F\n",
    "\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"{mean_cv:0.3f} ({std_cv:0.3f})\", \n",
    "      f\"fit: {fit_time:0.2f} secs pred: {score_time:0.2f} secs\") #G\n",
    "\n",
    "#A creating a scoring function using the accuracy_score metric\n",
    "#B creating a 5-fold cross-validation iterator with shuffling and a fixed random state\n",
    "#C creating an instance of a Support Vector Classifier from the GPU-accelerated cuML library with specified hyperparameters\n",
    "#D defining a ColumnTransformer to preprocess features, applying one-hot encoding to categorical features with low cardinality and standardization to numerical features\n",
    "#E creating a pipeline that sequentially applies the column transformation and the model to the data\n",
    "#F performing cross-validation on the data using the defined pipeline, with accuracy scoring\n",
    "#G  printing the mean and standard deviation of test scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
